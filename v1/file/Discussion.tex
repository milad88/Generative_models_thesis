%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Chapter3


\pagestyle{fancy} 
\chapter{Discussion}
\label{cha:3}
\vspace{1cm}

Going through the different frameworks we have seen in the previous section, we could notice that sometimes the goal of some researches are the same, like to find the probability distribution of data, or to maximize the total returned reward, generate new data instances, but the various authors were making different choices of the available techniques to achieve there goal in solving the task. We could explain these choices by making one step back and have a look on the data. Firstly the question that should be made is \textacutedbl what is the raw data the framework is going to cope with?\textgravedbl. The data we have seen are of different natures like trajectories, images, sensory data, grasp configuration and so on. Posting this question initially leads to figure out what are the space dimensions to deal with, and gives place to additional questions like \textacutedbl should we move to latent space?\textgravedbl in case it is high-dimensional like images. Another main question is \textacutedbl How big is the dataset?\textgravedbl this one is very important impact on the choice to make on the technique to use for the generative modeling, I discovered that when the dataset to base on the not large enough, means that it is more opportune to know probability distribution to generate new data instances from, so the choice of VAEs~\ref{cha:VAE} with reparameterizing trick~\ref{cha:VAE_REparam} in this case should be a good fit. Nevertheless, VAEs struggles to find a complex probability distribution in situations where the dataset is high-dimensional and composed of variables that vary in wild ranges, to overcome this kind of issue the GMM~\ref{cha:GMM} approach may fit better, given the property of GMM to combine $K$ probability distributions components to represent a final probability distribution that fits more efficiently the dataset. Moreover, in human cloning and/or learn from demonstrations tasks, where data are collect by making an expert to behave or execute actions in environment to achieve the goal of the task, this collected dataset is usually small for both learning process of the agent given some demonstrations, or cloning an expert behavior to achieve the required task. In this kind of situations where the amount of data available is not big enough, VAEs still not a good choice unless we follow the idea of moving to the latent space, then VAEs is the best option taking advantage its nice probabilistic formulation they come with as a result of maximizing a lower bound on the log-likelihood. Working in latent space is another approach that can circumvent the high-dimension real-world data. VAE naturally collapses most dimensions in the latent representations, and generally getting very interpretable dimensions out, even though the training dynamics are generally a bit weird. VAEs are used as well to learn the data representation like in~\cite{finn2016deep} which is a reinforcement learning application to robotic manipulation tasks. The authors were interested in knowing the spatial feature representation of the environment, these spatial features are the configurations of objects in the scene. The bottleneck of the autoencoder was modified in such way the spatial representation is learned. VAE has shown its ability as well as a generative model like in~\cite{eslami2016attend} formalizing a framework called \textit{Attend, infer, repeat} for efficient variational inference in latent spaces of variable dimensionality. The key idea of this paper is to treat inference as an iterative process, implemented as a recurrent neural network that attends to one object
at a time, and learns to use an appropriate number of inference steps for each image. VAE as a generative model is able to compete with GAN which is the most interesting idea in machine learning of the last 10 as Yann LeCun, Director of AI Research at Facebook AI claims. GANs is a superior model with respect to VAEs because they are better at generating visual features this superiority conduct to say that the adversarial loss is better than mean-squared loss. The difference that products this superiority is that VAE can spread the probability mass to places it might not make sense, whereas GAN models may never explore. Later, a cooperation between VAE and GAN has been done in~\cite{rahmatizadeh2018vision} mentioned in~\ref{sec:GAN-VAEs} which is one of the most advanced paper I read during this survey, that represent the state of art of robot manipulation tasks. it demonstrated how it is possible to learn complex manipulation tasks from user demonstrations, such as picking up a towel, wiping an object, and depositing the towel to its previous position, entirely from raw images with direct behavior cloning and outputs the joint configuration of the robot. \\
After the spread of GANs, their influence reached as well to reinforcement learning algorithms, specially those who follow the actor-critic approach like TRPO and DDPG. However GANS could be interpreted as an actor-critic approach, where the generator should learn the policy and the discriminator acts the critic that returns a feedback in such a way both generator/actor-discriminator/critic improve by the time goes on. Generally speaking this is what happens in all RL approaches that exploit the GANs architecture, like in GAIL~\cite{DBLP:journals/corr/HoE16} which is designed to imitate an expert behavior. The generator in this case is trying to generate trajectories as much similar to the expert ones, until the discriminator could distinguish between them, in other word a saddle point is found. This idea repeats itself each time a framework would like to achieve a cooperation between RL and GAN, as we have seen as well in SI-GARL~\cite{liu2019self}.


\clearpage{\pagestyle{empty}\cleardoublepage}